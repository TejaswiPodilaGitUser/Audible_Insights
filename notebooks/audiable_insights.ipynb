{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "RAW_DATA_PATH = \"../data/raw\"\n",
    "CLEANED_DATA_PATH = \"../data/cleaned\"\n",
    "\n",
    "# Ensure cleaned directory exists\n",
    "os.makedirs(CLEANED_DATA_PATH, exist_ok=True)\n",
    "\n",
    "# Load datasets\n",
    "df_basic = pd.read_csv(f\"{RAW_DATA_PATH}/Audible_Catlog.csv\")\n",
    "df_advanced = pd.read_csv(f\"{RAW_DATA_PATH}/Audible_Catlog_Advanced_Features.csv\")\n",
    "df_processed = pd.read_csv(\"../data/processed/audible_catalog_processed.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Dataset Columns: Index(['Book Name', 'Author', 'Rating', 'Number of Reviews', 'Price'], dtype='object')\n",
      "Advanced Dataset Columns: Index(['Book Name', 'Author', 'Rating', 'Number of Reviews', 'Price',\n",
      "       'Description', 'Listening Time', 'Ranks and Genre'],\n",
      "      dtype='object')\n",
      "Processed Dataset Columns: Index(['Book Name', 'Author', 'Rating', 'Number of Reviews', 'Price',\n",
      "       'Description', 'Listening Time (mins)', 'Main Genre', 'Top Rank',\n",
      "       'Is Free', 'Is Audible'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Debugging: Print column names\n",
    "print(\"Basic Dataset Columns:\", df_basic.columns)\n",
    "print(\"Advanced Dataset Columns:\", df_advanced.columns)\n",
    "print(\"Processed Dataset Columns:\", df_processed.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values in Basic Dataset:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "Columns with missing values in Advanced Dataset:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "Columns with missing values in Processed Dataset:\n",
      "Main Genre    1750\n",
      "Top Rank      1750\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns with missing values in Basic Dataset:\")\n",
    "print(df_basic.isnull().sum()[df_basic.isnull().sum() > 0])\n",
    "\n",
    "print(\"\\nColumns with missing values in Advanced Dataset:\")\n",
    "print(df_advanced.isnull().sum()[df_advanced.isnull().sum() > 0])\n",
    "\n",
    "print(\"\\nColumns with missing values in Processed Dataset:\")\n",
    "print(df_processed.isnull().sum()[df_processed.isnull().sum() > 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize column names (remove spaces, lowercase)\n",
    "df_basic.columns = df_basic.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2100817155.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdf = pd.read_csv(../data/processed/audible_catalog_processed.csv)\u001b[39m\n                     ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Book Name', 'Author', 'Rating', 'Number of Reviews', 'Price'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_basic.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(\"Listening Time\" in df_basic.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"The column 'Listening Time' is missing. Check dataset formatting!\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Check if 'Listening Time' exists\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mListening Time\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df_basic.columns:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mThe column \u001b[39m\u001b[33m'\u001b[39m\u001b[33mListening Time\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is missing. Check dataset formatting!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Convert 'Listening Time' to minutes\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconvert_listening_time\u001b[39m(time_str):\n",
      "\u001b[31mKeyError\u001b[39m: \"The column 'Listening Time' is missing. Check dataset formatting!\""
     ]
    }
   ],
   "source": [
    "# Check if 'Listening Time' exists\n",
    "if \"Listening Time\" not in df_basic.columns:\n",
    "    raise KeyError(\"The column 'Listening Time' is missing. Check dataset formatting!\")\n",
    "\n",
    "# Convert 'Listening Time' to minutes\n",
    "def convert_listening_time(time_str):\n",
    "    if pd.isna(time_str):\n",
    "        return None\n",
    "    time_parts = time_str.split(\" \")\n",
    "    hours = int(time_parts[0]) if \"hour\" in time_parts else 0\n",
    "    minutes = int(time_parts[3]) if \"minute\" in time_parts else 0\n",
    "    return hours * 60 + minutes\n",
    "\n",
    "df_basic[\"Listening Time (mins)\"] = df_basic[\"Listening Time\"].apply(convert_listening_time)\n",
    "\n",
    "# Save cleaned file\n",
    "df_basic.to_csv(f\"{CLEANED_DATA_PATH}/audible_catalog_cleaned.csv\", index=False)\n",
    "print(\"Data preprocessing completed successfully! 🚀\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Number of Reviews</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Think Like a Monk: The Secret of How to Harnes...</td>\n",
       "      <td>Jay Shetty</td>\n",
       "      <td>4.9</td>\n",
       "      <td>313.0</td>\n",
       "      <td>10080.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ikigai: The Japanese Secret to a Long and Happ...</td>\n",
       "      <td>Héctor García</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3658.0</td>\n",
       "      <td>615.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Subtle Art of Not Giving a F*ck: A Counter...</td>\n",
       "      <td>Mark Manson</td>\n",
       "      <td>4.4</td>\n",
       "      <td>20174.0</td>\n",
       "      <td>10378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Atomic Habits: An Easy and Proven Way to Build...</td>\n",
       "      <td>James Clear</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4614.0</td>\n",
       "      <td>888.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Life's Amazing Secrets: How to Find Balance an...</td>\n",
       "      <td>Gaur Gopal Das</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4302.0</td>\n",
       "      <td>1005.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Book Name          Author  Rating  \\\n",
       "0  Think Like a Monk: The Secret of How to Harnes...      Jay Shetty     4.9   \n",
       "1  Ikigai: The Japanese Secret to a Long and Happ...   Héctor García     4.6   \n",
       "2  The Subtle Art of Not Giving a F*ck: A Counter...     Mark Manson     4.4   \n",
       "3  Atomic Habits: An Easy and Proven Way to Build...     James Clear     4.6   \n",
       "4  Life's Amazing Secrets: How to Find Balance an...  Gaur Gopal Das     4.6   \n",
       "\n",
       "   Number of Reviews    Price  \n",
       "0              313.0  10080.0  \n",
       "1             3658.0    615.0  \n",
       "2            20174.0  10378.0  \n",
       "3             4614.0    888.0  \n",
       "4             4302.0   1005.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_basic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Book Name', 'Author', 'Rating', 'Number of Reviews', 'Price'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_basic.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Book Name', 'Author', 'Rating', 'Number of Reviews', 'Price',\n",
       "       'Description', 'Listening Time', 'Ranks and Genre'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_advanced.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique Ratings: [ 4.9  4.6  4.4  4.1  4.5  3.6  5.   4.   4.2  4.8  4.7  3.4 -1.   3.9\n",
      "  4.3  3.   3.8  2.5  2.   3.5  2.4  3.1  1.   3.2  3.7  3.3  2.9  1.9\n",
      "  2.6  2.7]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nUnique Ratings:\", df_advanced[\"Rating\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating\n",
      "-1.0    421\n",
      " 1.0      7\n",
      " 1.9      1\n",
      " 2.0      3\n",
      " 2.4      2\n",
      " 2.5      4\n",
      " 2.6      4\n",
      " 2.7      3\n",
      " 2.9      3\n",
      " 3.0     12\n",
      " 3.1      7\n",
      " 3.2      6\n",
      " 3.3      6\n",
      " 3.4     15\n",
      " 3.5     14\n",
      " 3.6     15\n",
      " 3.7     35\n",
      " 3.8     35\n",
      " 3.9     56\n",
      " 4.0    108\n",
      " 4.1    143\n",
      " 4.2    232\n",
      " 4.3    357\n",
      " 4.4    507\n",
      " 4.5    665\n",
      " 4.6    760\n",
      " 4.7    626\n",
      " 4.8    269\n",
      " 4.9     49\n",
      " 5.0     99\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of each rating\n",
    "rating_counts = df_advanced[\"Rating\"].value_counts().sort_index()\n",
    "print(rating_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating\n",
       "-1.0    421\n",
       " 1.0      7\n",
       " 1.9      1\n",
       " 2.0      3\n",
       " 2.4      2\n",
       " 2.5      4\n",
       " 2.6      4\n",
       " 2.7      3\n",
       " 2.9      3\n",
       " 3.0     12\n",
       " 3.1      7\n",
       " 3.2      6\n",
       " 3.3      6\n",
       " 3.4     15\n",
       " 3.5     14\n",
       " 3.6     15\n",
       " 3.7     35\n",
       " 3.8     35\n",
       " 3.9     56\n",
       " 4.0    108\n",
       " 4.1    143\n",
       " 4.2    232\n",
       " 4.3    357\n",
       " 4.4    507\n",
       " 4.5    665\n",
       " 4.6    760\n",
       " 4.7    626\n",
       " 4.8    269\n",
       " 4.9     49\n",
       " 5.0     99\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_advanced[\"Rating\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Reviews\n",
      "1.0        61\n",
      "2.0        43\n",
      "3.0        46\n",
      "4.0        30\n",
      "5.0        24\n",
      "           ..\n",
      "33293.0     1\n",
      "38310.0     1\n",
      "40958.0     1\n",
      "43869.0     1\n",
      "70122.0     1\n",
      "Name: count, Length: 1544, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of each rating\n",
    "rating_counts = df_advanced[\"Number of Reviews\"].value_counts().sort_index()\n",
    "print(rating_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'split_ranks_genre' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mRanks and Genre\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df_advanced.columns:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     df_advanced[[\u001b[33m\"\u001b[39m\u001b[33mRanks\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mGenres\u001b[39m\u001b[33m\"\u001b[39m]] = \u001b[43mdf_advanced\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRanks and Genre\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_ranks_genre\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     df_advanced.drop(columns=[\u001b[33m\"\u001b[39m\u001b[33mRanks and Genre\u001b[39m\u001b[33m\"\u001b[39m], inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Display the first few rows after splitting\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/audiableinsights/lib/python3.12/site-packages/pandas/core/series.py:4924\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4789\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4790\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4791\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4796\u001b[39m     **kwargs,\n\u001b[32m   4797\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4798\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4799\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4800\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4915\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4916\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4917\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4918\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4919\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4920\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4921\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4922\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4923\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4924\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/audiableinsights/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1424\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1426\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1427\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/audiableinsights/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1501\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1502\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1503\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1504\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1505\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1506\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1507\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1508\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1509\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1511\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1512\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1513\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1514\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/audiableinsights/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    918\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    919\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/audiableinsights/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mlib.pyx:2972\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mRanks and Genre\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df_advanced.columns:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     df_advanced[[\u001b[33m\"\u001b[39m\u001b[33mRanks\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mGenres\u001b[39m\u001b[33m\"\u001b[39m]] = df_advanced[\u001b[33m\"\u001b[39m\u001b[33mRanks and Genre\u001b[39m\u001b[33m\"\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: pd.Series(\u001b[43msplit_ranks_genre\u001b[49m(x)))\n\u001b[32m      3\u001b[39m     df_advanced.drop(columns=[\u001b[33m\"\u001b[39m\u001b[33mRanks and Genre\u001b[39m\u001b[33m\"\u001b[39m], inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Display the first few rows after splitting\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'split_ranks_genre' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if \"Ranks and Genre\" in df_advanced.columns:\n",
    "    df_advanced[[\"Ranks\", \"Genres\"]] = df_advanced[\"Ranks and Genre\"].apply(lambda x: pd.Series(split_ranks_genre(x)))\n",
    "    df_advanced.drop(columns=[\"Ranks and Genre\"], inplace=True)\n",
    "\n",
    "# Display the first few rows after splitting\n",
    "print(\"\\nAfter Splitting:\")\n",
    "display(df_advanced.head())\n",
    "\n",
    "\n",
    "\n",
    "def split_ranks_genre(value):\n",
    "    \"\"\"Splits 'Ranks and Genre' column into 'Ranks' and 'Genres'.\"\"\"\n",
    "    if pd.isna(value):\n",
    "        return pd.NA, pd.NA\n",
    "\n",
    "    # Remove unnecessary text\n",
    "    value = re.sub(r\"in Audible Audiobooks & Originals \\(See Top 100 in Audible Audiobooks & Originals\\)\", \"\", value)\n",
    "\n",
    "    # Extract \"Rank in Genre\"\n",
    "    rank_genre_pairs = re.findall(r\"(#\\d+) in ([^,]+)\", value)\n",
    "\n",
    "    ranks = []\n",
    "    genres = []\n",
    "\n",
    "    for rank, genre in rank_genre_pairs:\n",
    "        ranks.append(rank)\n",
    "        genres.append(f\"{rank} in {genre.strip()}\")  \n",
    "\n",
    "    return \", \".join(ranks) if ranks else pd.NA, \", \".join(genres) if genres else pd.NA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Columns in df_basic: ['Book Name', 'Author', 'Rating', 'Number of Reviews', 'Price']\n",
      "✅ Columns in df_advanced: ['Book Name', 'Author', 'Rating', 'Number of Reviews', 'Price', 'Description', 'Listening Time', 'Ranks and Genre']\n",
      "🔄 Replacements in df_basic (Audible_Catalog.csv): 3 missing values filled.\n",
      "✅ Cleaned basic dataset saved at: ../data/cleaned/audible_catalog_cleaned.csv\n",
      "🔄 Replacements in df_advanced (Audible_Catalog_Advanced_Features.csv): 427 missing values filled.\n",
      "✅ Cleaned advanced dataset saved at: ../data/cleaned/audible_catalog_advanced_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define file paths\n",
    "RAW_DATA_PATH = \"../data/raw\"\n",
    "CLEANED_DATA_PATH = \"../data/cleaned\"\n",
    "\n",
    "# Ensure cleaned directory exists\n",
    "os.makedirs(CLEANED_DATA_PATH, exist_ok=True)\n",
    "\n",
    "# Load datasets\n",
    "df_basic = pd.read_csv(f\"{RAW_DATA_PATH}/Audible_Catlog.csv\")\n",
    "df_advanced = pd.read_csv(f\"{RAW_DATA_PATH}/Audible_Catlog_Advanced_Features.csv\")\n",
    "\n",
    "# Standardize column names (only strip spaces)\n",
    "df_basic.columns = df_basic.columns.str.strip()\n",
    "df_advanced.columns = df_advanced.columns.str.strip()\n",
    "\n",
    "print(\"✅ Columns in df_basic:\", df_basic.columns.tolist())\n",
    "print(\"✅ Columns in df_advanced:\", df_advanced.columns.tolist())\n",
    "\n",
    "# ---- PROCESSING df_basic ---- #\n",
    "\n",
    "# Convert 'Rating' and 'Number of Reviews' to numeric\n",
    "if \"Rating\" in df_basic.columns and \"Number of Reviews\" in df_basic.columns:\n",
    "    df_basic[\"Rating\"] = pd.to_numeric(df_basic[\"Rating\"], errors=\"coerce\").fillna(df_basic[\"Rating\"].median())\n",
    "    df_basic[\"Number of Reviews\"] = pd.to_numeric(df_basic[\"Number of Reviews\"], errors=\"coerce\").fillna(0)\n",
    "    df_basic[\"Popularity Score\"] = (df_basic[\"Number of Reviews\"] * df_basic[\"Rating\"]).apply(lambda x: max(x, 1))\n",
    "else:\n",
    "    print(\"⚠️ Warning: 'Rating' or 'Number of Reviews' column not found in df_basic.\")\n",
    "\n",
    "# Count missing values before filling\n",
    "missing_before_basic = df_basic.isna().sum().sum()\n",
    "\n",
    "# Fill missing values using forward fill and backward fill\n",
    "df_basic.ffill(inplace=True)\n",
    "df_basic.bfill(inplace=True)\n",
    "\n",
    "# Count missing values after filling\n",
    "missing_after_basic = df_basic.isna().sum().sum()\n",
    "replacements_basic = missing_before_basic - missing_after_basic\n",
    "\n",
    "print(f\"🔄 Replacements in df_basic (Audible_Catalog.csv): {replacements_basic} missing values filled.\")\n",
    "\n",
    "# Remove duplicate rows\n",
    "df_basic.drop_duplicates(inplace=True)\n",
    "\n",
    "# Save cleaned Audible_Catalog.csv\n",
    "cleaned_basic_file = f\"{CLEANED_DATA_PATH}/audible_catalog_cleaned.csv\"\n",
    "df_basic.to_csv(cleaned_basic_file, index=False)\n",
    "print(f\"✅ Cleaned basic dataset saved at: {cleaned_basic_file}\")\n",
    "\n",
    "# ---- PROCESSING df_advanced ---- #\n",
    "\n",
    "# Convert 'Listening Time' to minutes\n",
    "def convert_listening_time(time_str):\n",
    "    if pd.isna(time_str) or not isinstance(time_str, str):\n",
    "        return None\n",
    "    time_parts = time_str.split(\" \")\n",
    "    hours, minutes = 0, 0\n",
    "    try:\n",
    "        if \"hour\" in time_parts:\n",
    "            hours = int(time_parts[0])\n",
    "        if \"minute\" in time_parts:\n",
    "            minutes = int(time_parts[-2])\n",
    "    except (ValueError, IndexError):\n",
    "        return None\n",
    "    return hours * 60 + minutes\n",
    "\n",
    "if \"Listening Time\" in df_advanced.columns:\n",
    "    df_advanced[\"Listening Time (mins)\"] = df_advanced[\"Listening Time\"].apply(convert_listening_time)\n",
    "    df_advanced.drop(columns=[\"Listening Time\"], inplace=True)\n",
    "else:\n",
    "    print(\"⚠️ Warning: 'Listening Time' column not found in df_advanced.\")\n",
    "\n",
    "# Extract main genre\n",
    "def extract_main_genre(ranks_genre):\n",
    "    if pd.isna(ranks_genre) or not isinstance(ranks_genre, str):\n",
    "        return None\n",
    "    genres = ranks_genre.split(\", \")\n",
    "    return genres[1] if len(genres) > 1 else genres[0]\n",
    "\n",
    "if \"Ranks and Genre\" in df_advanced.columns:\n",
    "    df_advanced[\"Main Genre\"] = df_advanced[\"Ranks and Genre\"].apply(extract_main_genre)\n",
    "    df_advanced.drop(columns=[\"Ranks and Genre\"], inplace=True)\n",
    "else:\n",
    "    print(\"⚠️ Warning: 'Ranks and Genre' column not found in df_advanced.\")\n",
    "\n",
    "# Count missing values before filling\n",
    "missing_before_advanced = df_advanced.isna().sum().sum()\n",
    "\n",
    "# Fill missing values using forward fill and backward fill\n",
    "df_advanced.ffill(inplace=True)\n",
    "df_advanced.bfill(inplace=True)\n",
    "\n",
    "# Count missing values after filling\n",
    "missing_after_advanced = df_advanced.isna().sum().sum()\n",
    "replacements_advanced = missing_before_advanced - missing_after_advanced\n",
    "\n",
    "print(f\"🔄 Replacements in df_advanced (Audible_Catalog_Advanced_Features.csv): {replacements_advanced} missing values filled.\")\n",
    "\n",
    "# Remove duplicate rows\n",
    "df_advanced.drop_duplicates(inplace=True)\n",
    "\n",
    "# Save cleaned Audible_Catalog_Advanced_Features.csv\n",
    "cleaned_advanced_file = f\"{CLEANED_DATA_PATH}/audible_catalog_advanced_cleaned.csv\"\n",
    "df_advanced.to_csv(cleaned_advanced_file, index=False)\n",
    "print(f\"✅ Cleaned advanced dataset saved at: {cleaned_advanced_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audiableinsights",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
